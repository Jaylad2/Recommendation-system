{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e774bd64-27a3-4b4f-89e1-52881d97bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  955k    0  2283    0     0   1635      0  0:09:58  0:00:01  0:09:57  1638\n",
      "  9  955k    9 91883    0     0  39941      0  0:00:24  0:00:02  0:00:22 40001\n",
      " 82  955k   82  788k    0     0   245k      0  0:00:03  0:00:03 --:--:--  245k\n",
      "100  955k  100  955k    0     0   296k      0  0:00:03  0:00:03 --:--:--  296k\n"
     ]
    }
   ],
   "source": [
    "# Data Citation:\n",
    "# F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on \n",
    "# Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19. \n",
    "\n",
    "! curl http://files.grouplens.org/datasets/movielens/ml-latest-small.zip -o ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43a05e1-49ba-45c9-95fa-bc573b8426fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('ml-latest-small.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb0f2e7-11ae-4efa-9b54-9eff2e38a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movies_df = pd.read_csv('data/ml-latest-small/movies.csv')\n",
    "ratings_df = pd.read_csv('data/ml-latest-small/ratings.csv')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f0c123-ab33-46b5-a2c7-92edfccdf730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of movies dataframe are: (9742, 3) \n",
      "The dimensions of ratings dataframe are: (100836, 4)\n"
     ]
    }
   ],
   "source": [
    "print('The dimensions of movies dataframe are:', movies_df.shape,'\\nThe dimensions of ratings dataframe are:', ratings_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a4170f6-927a-4d88-bd9c-58b629c62a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6038112b-737c-46a6-8d9d-f03395a579c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff99e0d2-cfa5-4342-bee9-981bc014f9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 610\n",
      "Number of unique movies: 9724\n",
      "The full rating matrix will have: 5931640 elements.\n",
      "----------\n",
      "Number of ratings: 100836\n",
      "Therefore:  1.6999683055613624 % of the matrix is filled.\n",
      "We have an incredibly sparse matrix to work with here.\n",
      "And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\n",
      "You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\n",
      "One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\n"
     ]
    }
   ],
   "source": [
    "movie_names = movies_df.set_index('movieId')['title'].to_dict()\n",
    "n_users = len(ratings_df.userId.unique())\n",
    "n_items = len(ratings_df.movieId.unique())\n",
    "print(\"Number of unique users:\", n_users)\n",
    "print(\"Number of unique movies:\", n_items)\n",
    "print(\"The full rating matrix will have:\", n_users*n_items, 'elements.')\n",
    "print('----------')\n",
    "print(\"Number of ratings:\", len(ratings_df))\n",
    "print(\"Therefore: \", len(ratings_df) / (n_users*n_items) * 100, '% of the matrix is filled.')\n",
    "print(\"We have an incredibly sparse matrix to work with here.\")\n",
    "print(\"And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\")\n",
    "print(\"You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\")\n",
    "print(\"One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63a4c35f-9b9c-4868-aeee-20a91327b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors) \n",
    "       \n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors) \n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # matrix multiplication\n",
    "        users, items = data[:,0], data[:,1]\n",
    "        return (self.user_factors(users)*self.item_factors(items)).sum(1)\n",
    "   \n",
    "    \n",
    "    def predict(self, user, item):\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5233a0ae-d8a1-454e-90cc-bb5c3b2422b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness\n",
    "\n",
    "# Note: This isn't 'good' practice, in a MLops sense but we'll roll with this since the data is already loaded in memory.\n",
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.ratings = ratings_df.copy()\n",
    "        \n",
    "        # Extract all user IDs and movie IDs\n",
    "        users = ratings_df.userId.unique()\n",
    "        movies = ratings_df.movieId.unique()\n",
    "        \n",
    "        #--- Producing new continuous IDs for users and movies ---\n",
    "        \n",
    "        # Unique values : index\n",
    "        self.userid2idx = {o:i for i,o in enumerate(users)}\n",
    "        self.movieid2idx = {o:i for i,o in enumerate(movies)}\n",
    "        \n",
    "        # Obtained continuous ID for users and movies\n",
    "        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n",
    "        self.idx2movieid = {i:o for o,i in self.movieid2idx.items()}\n",
    "        \n",
    "        # return the id from the indexed values as noted in the lambda function down below.\n",
    "        self.ratings.movieId = ratings_df.movieId.apply(lambda x: self.movieid2idx[x])\n",
    "        self.ratings.userId = ratings_df.userId.apply(lambda x: self.userid2idx[x])\n",
    "        \n",
    "        \n",
    "        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n",
    "        self.y = self.ratings['rating'].values\n",
    "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors (ready for torch models.)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2179f24b-53a4-4357-a0aa-a6cb43b87ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is running on GPU: False\n",
      "MatrixFactorization(\n",
      "  (user_factors): Embedding(610, 8)\n",
      "  (item_factors): Embedding(9724, 8)\n",
      ")\n",
      "user_factors.weight tensor([[0.0467, 0.0319, 0.0070,  ..., 0.0107, 0.0044, 0.0497],\n",
      "        [0.0496, 0.0168, 0.0038,  ..., 0.0199, 0.0245, 0.0019],\n",
      "        [0.0373, 0.0286, 0.0023,  ..., 0.0252, 0.0486, 0.0458],\n",
      "        ...,\n",
      "        [0.0120, 0.0394, 0.0307,  ..., 0.0071, 0.0481, 0.0200],\n",
      "        [0.0239, 0.0055, 0.0484,  ..., 0.0435, 0.0096, 0.0325],\n",
      "        [0.0399, 0.0072, 0.0494,  ..., 0.0490, 0.0044, 0.0276]])\n",
      "item_factors.weight tensor([[0.0026, 0.0024, 0.0243,  ..., 0.0300, 0.0493, 0.0394],\n",
      "        [0.0019, 0.0196, 0.0397,  ..., 0.0078, 0.0437, 0.0240],\n",
      "        [0.0327, 0.0099, 0.0072,  ..., 0.0362, 0.0338, 0.0320],\n",
      "        ...,\n",
      "        [0.0495, 0.0093, 0.0205,  ..., 0.0368, 0.0440, 0.0020],\n",
      "        [0.0456, 0.0152, 0.0362,  ..., 0.0273, 0.0353, 0.0286],\n",
      "        [0.0399, 0.0150, 0.0020,  ..., 0.0186, 0.0107, 0.0195]])\n"
     ]
    }
   ],
   "source": [
    "um_epochs = 128\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Is running on GPU:\", cuda)\n",
    "\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "# GPU enable if you have a GPU...\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# MSE loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# ADAM optimizier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train data\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd50c728-3007-49c0-92ee-b5535326dd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:02<00:23,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #0 Loss: 11.070508123049276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:04<00:19,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #1 Loss: 4.744322446397113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:07<00:16,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #2 Loss: 2.4742433536173727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:09<00:14,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #3 Loss: 1.7206287076176725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:12<00:12,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #4 Loss: 1.3456823957450499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:14<00:09,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #5 Loss: 1.1282073735888234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:16<00:07,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #6 Loss: 0.9914843270621324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:19<00:04,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #7 Loss: 0.9004127735716437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:21<00:02,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #8 Loss: 0.8372858684831465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:24<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #9 Loss: 0.7922594704603786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 10  # Set this to the desired number of epochs\n",
    "\n",
    "# Assuming the following variables are defined: \n",
    "# model, optimizer, loss_fn, train_loader, and cuda (whether to use GPU or CPU)\n",
    "\n",
    "for it in tqdm(range(num_epochs)):  # Add tqdm here to create the progress bar\n",
    "    losses = []\n",
    "    for x, y in train_loader:  # Iterate through the training data\n",
    "        if cuda:  # Check if CUDA (GPU) is available\n",
    "            x, y = x.cuda(), y.cuda()  # Move data to GPU\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(x)  # Forward pass\n",
    "        loss = loss_fn(outputs.squeeze(), y.type(torch.float32))  # Calculate the loss\n",
    "        losses.append(loss.item())  # Append loss value\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update model weights\n",
    "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))  # Print average loss for each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b05441-0155-4a21-9068-7d245a0348d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_factors.weight tensor([[1.2977, 1.2733, 1.2599,  ..., 1.2630, 1.2706, 1.2864],\n",
      "        [1.0415, 1.0143, 0.9919,  ..., 1.0199, 1.0132, 1.0043],\n",
      "        [0.6200, 0.6192, 0.5671,  ..., 0.6157, 0.6153, 0.6018],\n",
      "        ...,\n",
      "        [0.9778, 0.9970, 0.9951,  ..., 0.9543, 1.0074, 0.9900],\n",
      "        [0.9670, 0.9370, 0.9887,  ..., 0.9694, 0.9451, 0.9660],\n",
      "        [1.2015, 1.1729, 1.2145,  ..., 1.2281, 1.2031, 1.2076]])\n",
      "item_factors.weight tensor([[0.4630, 0.4663, 0.4864,  ..., 0.4873, 0.4936, 0.5057],\n",
      "        [0.3657, 0.3726, 0.3963,  ..., 0.3652, 0.3956, 0.3878],\n",
      "        [0.4937, 0.4784, 0.4732,  ..., 0.4914, 0.4871, 0.4914],\n",
      "        ...,\n",
      "        [0.2625, 0.2224, 0.2332,  ..., 0.2497, 0.2576, 0.2149],\n",
      "        [0.2607, 0.2303, 0.2512,  ..., 0.2424, 0.2509, 0.2436],\n",
      "        [0.2495, 0.2246, 0.2115,  ..., 0.2283, 0.2208, 0.2291]])\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "uw = 0\n",
    "iw = 0 \n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        if c == 0:\n",
    "          uw = param.data\n",
    "          c +=1\n",
    "        else:\n",
    "          iw = param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17597a41-720e-4a7f-95ce-3264575ac9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62cdaa7d-5c0e-4d0a-8094-e807aede2733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trained_movie_embeddings) # unique movie factor weights\n",
    "     rom sklearn.cluster import KMeans\n",
    "# Fit the clusters based on the movie weights\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed9aa7a1-90de-4c66-abc3-2335d562aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Fit the clusters based on the movie weights\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a409079-426b-4612-9202-abadc3a3525a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #0\n",
      "\t Coneheads (1993)\n",
      "\t Mortal Kombat (1995)\n",
      "\t Flintstones, The (1994)\n",
      "\t Striptease (1996)\n",
      "\t Hollow Man (2000)\n",
      "\t Free Willy (1993)\n",
      "\t Showgirls (1995)\n",
      "\t Hulk (2003)\n",
      "\t Daredevil (2003)\n",
      "\t Bio-Dome (1996)\n",
      "Cluster #1\n",
      "\t Jurassic Park (1993)\n",
      "\t Aladdin (1992)\n",
      "\t True Lies (1994)\n",
      "\t Back to the Future (1985)\n",
      "\t Speed (1994)\n",
      "\t Shrek (2001)\n",
      "\t Dances with Wolves (1990)\n",
      "\t Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "\t Beauty and the Beast (1991)\n",
      "\t Die Hard (1988)\n",
      "Cluster #2\n",
      "\t Anaconda (1997)\n",
      "\t Speed 2: Cruise Control (1997)\n",
      "\t Battlefield Earth (2000)\n",
      "\t Superman IV: The Quest for Peace (1987)\n",
      "\t Karate Kid, Part III, The (1989)\n",
      "\t Sister Act 2: Back in the Habit (1993)\n",
      "\t Ultraviolet (2006)\n",
      "\t Dungeons & Dragons (2000)\n",
      "\t Rambo III (1988)\n",
      "\t Problem Child (1990)\n",
      "Cluster #3\n",
      "\t Ace Ventura: Pet Detective (1994)\n",
      "\t Mask, The (1994)\n",
      "\t Star Wars: Episode I - The Phantom Menace (1999)\n",
      "\t Batman Forever (1995)\n",
      "\t Dumb & Dumber (Dumb and Dumber) (1994)\n",
      "\t Waterworld (1995)\n",
      "\t Net, The (1995)\n",
      "\t Cliffhanger (1993)\n",
      "\t Natural Born Killers (1994)\n",
      "\t Armageddon (1998)\n",
      "Cluster #4\n",
      "\t Police Academy: Mission to Moscow (1994)\n",
      "\t House Party 2 (1991)\n",
      "\t Wicker Man, The (2006)\n",
      "\t American Pie Presents The Naked Mile (American Pie 5: The Naked Mile) (2006)\n",
      "\t Fifty Shades of Grey (2015)\n",
      "\t Yogi Bear (2010)\n",
      "\t From Justin to Kelly (2003)\n",
      "\t Disaster Movie (2008)\n",
      "\t Date Movie (2006)\n",
      "\t Fathers' Day (1997)\n",
      "Cluster #5\n",
      "\t Wild Wild West (1999)\n",
      "\t Batman & Robin (1997)\n",
      "\t Godzilla (1998)\n",
      "\t I Know What You Did Last Summer (1997)\n",
      "\t Super Mario Bros. (1993)\n",
      "\t Inspector Gadget (1999)\n",
      "\t Honey, I Blew Up the Kid (1992)\n",
      "\t I Still Know What You Did Last Summer (1998)\n",
      "\t Rocky V (1990)\n",
      "\t Big Momma's House (2000)\n",
      "Cluster #6\n",
      "\t Independence Day (a.k.a. ID4) (1996)\n",
      "\t Batman (1989)\n",
      "\t Men in Black (a.k.a. MIB) (1997)\n",
      "\t Mission: Impossible (1996)\n",
      "\t Mrs. Doubtfire (1993)\n",
      "\t Stargate (1994)\n",
      "\t Titanic (1997)\n",
      "\t Pretty Woman (1990)\n",
      "\t Twister (1996)\n",
      "\t Spider-Man (2002)\n",
      "Cluster #7\n",
      "\t Forrest Gump (1994)\n",
      "\t Shawshank Redemption, The (1994)\n",
      "\t Pulp Fiction (1994)\n",
      "\t Silence of the Lambs, The (1991)\n",
      "\t Matrix, The (1999)\n",
      "\t Star Wars: Episode IV - A New Hope (1977)\n",
      "\t Braveheart (1995)\n",
      "\t Terminator 2: Judgment Day (1991)\n",
      "\t Schindler's List (1993)\n",
      "\t Fight Club (1999)\n",
      "Cluster #8\n",
      "\t Home Alone (1990)\n",
      "\t Ace Ventura: When Nature Calls (1995)\n",
      "\t Nutty Professor, The (1996)\n",
      "\t Mission: Impossible II (2000)\n",
      "\t Charlie's Angels (2000)\n",
      "\t Honey, I Shrunk the Kids (1989)\n",
      "\t Lost World: Jurassic Park, The (1997)\n",
      "\t Austin Powers in Goldmember (2002)\n",
      "\t Blair Witch Project, The (1999)\n",
      "\t Miss Congeniality (2000)\n",
      "Cluster #9\n",
      "\t Spice World (1997)\n",
      "\t Stuart Saves His Family (1995)\n",
      "\t Catwoman (2004)\n",
      "\t Jason X (2002)\n",
      "\t Problem Child 2 (1991)\n",
      "\t Eye of the Beholder (1999)\n",
      "\t Pokémon the Movie 2000 (2000)\n",
      "\t Look Who's Talking Now (1993)\n",
      "\t Jaws 3-D (1983)\n",
      "\t Ernest Goes to Camp (1987)\n"
     ]
    }
   ],
   "source": [
    "for cluster in range(10):\n",
    "    print(\"Cluster #{}\".format(cluster))\n",
    "    movs = []\n",
    "    # Find movie indices belonging to the current cluster\n",
    "    for movidx in np.where(kmeans.labels_ == cluster)[0]:\n",
    "        movid = train_set.idx2movieid[movidx]\n",
    "        # Check how many ratings this movie has\n",
    "        rat_count = len(ratings_df.loc[ratings_df['movieId'] == movid])\n",
    "        movs.append((movie_names[movid], rat_count))\n",
    "    # Sort movies by rating count in descending order and print top 10\n",
    "    for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
    "        print(\"\\t\", mov[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
